{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD9gUQpaBxNa"
   },
   "source": [
    "# Detection de frelons à l'aide de l'algorithme YoloV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "2b0dfcca-1cd4-4c55-fcac-c8c65ba3b7ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eisti/Desktop/ING3/usecase1/UseCase_frelon_asiatique/yolov5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Image, clear_output  # librairie d'affichage des images\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "%cd yolov5\n",
    "from utils.downloads import gdrive_download\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDIhrBF0sPaM"
   },
   "source": [
    "# Mise en place du dataset\n",
    "\n",
    "Après avoir collecté des images dans 3 classes différentes (Frelons asiatiques, Frelons européens et autres insectes dont abeilles, guêpes et mouches), nous les avons labellisé en utilisant RoboFlow. On obtient alors une clé API qui nous permet de récupéré des données pré-formatées que l'on pourra utiliser simplement pour entrainer notre algorithme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ug_PhK1oqwQA",
    "outputId": "a55ae54a-8aed-4eb6-d60d-b5e9007aa3c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in useCaseHornet-2 to yolov5pytorch: 100% [5672017 / 5672017] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to useCaseHornet-2 in yolov5pytorch:: 100%|████| 474/474 [00:00<00:00, 2972.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"l7xZVOnY9MzH8MTMppTB\")\n",
    "project = rf.workspace().project(\"usecasehornet\")\n",
    "dataset = project.version(2).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZ3DmmGQztJj",
    "outputId": "084d7edd-6d95-4852-9ebd-191a042aadae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\r\n",
      "- asian\r\n",
      "- european\r\n",
      "- other\r\n",
      "nc: 3\r\n",
      "train: useCaseHornet-2/train/images\r\n",
      "val: useCaseHornet-2/valid/images\r\n"
     ]
    }
   ],
   "source": [
    "# informations sur le dataset utilisé\n",
    "%cat {dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwJx-2NHsYxT"
   },
   "source": [
    "# Définition des paramètres du modèle\n",
    "\n",
    "On définit ensuite les différents paramètres de notre modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dOPn9wjOAwwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classes : 3\n"
     ]
    }
   ],
   "source": [
    "# on récupère le nombre de classes de nos données\n",
    "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])\n",
    "print(\"Nombre de classes :\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Rvt5wilnDyX",
    "outputId": "d216e6fb-5b8c-4497-fd34-d12c8056ec82"
   },
   "outputs": [],
   "source": [
    "#this is the model configuration we will use for our tutorial \n",
    "#%cat models/yolov5m.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "t14hhyqdmw6O"
   },
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uDxebz13RdRA"
   },
   "outputs": [],
   "source": [
    "%%writetemplate models/custom_yolov5s.yaml\n",
    "\n",
    "# parameters\n",
    "nc: {num_classes}  # number of classes\n",
    "depth_multiple: 0.33  # model depth multiple\n",
    "width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "  - [10,13, 16,30, 33,23]  # P3/8\n",
    "  - [30,61, 62,45, 59,119]  # P4/16\n",
    "  - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, BottleneckCSP, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, BottleneckCSP, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, BottleneckCSP, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 head\n",
    "head:\n",
    "  [[-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "   [-1, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "   [-1, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUOiNLtMP5aG"
   },
   "source": [
    "# Entrainement sur nos données\n",
    "\n",
    "\n",
    "Here, we are able to pass a number of arguments:\n",
    "- **img:** define input image size\n",
    "- **batch:** determine batch size\n",
    "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
    "- **data:** set the path to our yaml file\n",
    "- **cfg:** specify our model configuration\n",
    "- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n",
    "- **name:** result names\n",
    "- **nosave:** only save the final checkpoint\n",
    "- **cache:** cache images for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "f5537b2f-9633-44e6-9f5b-ed61baae2c1b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "# train yolov5s on custom data for 100 epochs\n",
    "# time its performance\n",
    "%%time\n",
    "%cd /content/yolov5/\n",
    "!python train.py --img 416 --batch 16 --epochs 100 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJVs_4zEeVbF"
   },
   "source": [
    "# Evaluate Custom YOLOv5 Detector Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KN5ghjE6ZWh"
   },
   "source": [
    "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
    "\n",
    "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bOy5KI2ncnWd",
    "outputId": "483bd585-26cf-46ab-9285-f84f7ba1f308"
   },
   "outputs": [],
   "source": [
    "# Start tensorboard\n",
    "# Launch after you have started training\n",
    "# logs save in the folder \"runs\"\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "C60XAsyv6OPe",
    "outputId": "ddfe137f-d6c7-4621-a6de-0d834e6205b3"
   },
   "outputs": [],
   "source": [
    "# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n",
    "from utils.plots import plot_results  # plot results.txt as results.png\n",
    "Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLI1JmHU7B0l"
   },
   "source": [
    "### Curious? Visualize Our Training Data with Labels\n",
    "\n",
    "After training starts, view `train*.jpg` images to see training images, labels and augmentation effects.\n",
    "\n",
    "Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PF9MLHDb7tB6",
    "outputId": "bea11e72-080f-4516-d30b-96162ad7a3a9"
   },
   "outputs": [],
   "source": [
    "# first, display our ground truth data\n",
    "print(\"GROUND TRUTH TRAINING DATA:\")\n",
    "Image(filename='/content/yolov5/runs/train/yolov5s_results/test_batch0_labels.jpg', width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "W40tI99_7BcH",
    "outputId": "1491d877-c426-4dff-d32a-fb91b1e5feb7"
   },
   "outputs": [],
   "source": [
    "# print out an augmented training example\n",
    "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
    "Image(filename='/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3qM6T0W53gh"
   },
   "source": [
    "#Run Inference  With Trained Weights\n",
    "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "yIEwt5YLeQ7P",
    "outputId": "7b3e52bc-4888-48de-c1d0-9e84a4f9d07f"
   },
   "outputs": [],
   "source": [
    "# trained weights are saved by default in our weights folder\n",
    "%ls runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4SyOWS80qR32",
    "outputId": "0e523144-c731-4c76-c51c-6628c76e8e59"
   },
   "outputs": [],
   "source": [
    "%ls runs/train/yolov5s_results/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9nmZZnWOgJ2S",
    "outputId": "4a9b2b6f-5972-45f5-9428-8d9ed8a64677"
   },
   "outputs": [],
   "source": [
    "# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
    "# use the best weights!\n",
    "%cd /content/yolov5/\n",
    "!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source useCaseHornet-2/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "odKEqYtTgbRc"
   },
   "outputs": [],
   "source": [
    "#display inference on ALL test images\n",
    "#this looks much better with longer training above\n",
    "\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob('/content/yolov5/runs/detect/exp2/*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uPq9mVgiBql"
   },
   "source": [
    "# Export Trained Weights for Future Inference\n",
    "\n",
    "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YH4CTzDRh00g"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1x_wg3VeiXMW"
   },
   "outputs": [],
   "source": [
    "%cp /content/yolov5/runs/train/yolov5s_results/weights/best.pt /content/gdrive/My\\ Drive"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Roboflow-YOLOv5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
